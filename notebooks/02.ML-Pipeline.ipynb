{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline for Astronomical NER Model\n",
    "\n",
    "## Objective\n",
    "\n",
    "This notebook implements a complete machine learning pipeline for training, optimizing, and evaluating a spaCy Named Entity Recognition (NER) model to identify astronomical objects in scientific text.\n",
    "\n",
    "## Pipeline Overview\n",
    "\n",
    "1. **Data Loading & Preprocessing**: Load the annotated training data from the previous notebook\n",
    "2. **Train/Validation/Test Split**: Create balanced splits for training, hyperparameter tuning, and final evaluation\n",
    "3. **Model Training**: Train spaCy NER model with configurable parameters\n",
    "4. **Hyperparameter Optimization**: Use systematic search to find optimal model parameters\n",
    "5. **Model Evaluation**: Comprehensive evaluation using precision, recall, F1-score, and entity-level metrics\n",
    "6. **Model Persistence**: Save trained models for deployment\n",
    "\n",
    "## Key Features\n",
    "\n",
    "- Stratified splitting to maintain entity distribution across splits\n",
    "- Configurable training parameters (dropout, learning rate, batch size)\n",
    "- Early stopping and learning rate scheduling\n",
    "- Comprehensive evaluation metrics including per-entity analysis\n",
    "- Model versioning and experiment tracking capabilities\n",
    "- Error analysis and misclassification detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict, Any, Optional\n",
    "from collections import defaultdict, Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# spaCy imports\n",
    "import spacy\n",
    "from spacy.training import Example\n",
    "from spacy.util import minibatch, compounding\n",
    "from spacy.lang.en import English\n",
    "\n",
    "# Evaluation imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration and Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data path: ../data/ner_data/spacy_ner_data.json\n",
      "Models directory: ../data/models\n",
      "Configuration: {'train_split': 0.7, 'val_split': 0.15, 'test_split': 0.15, 'n_iter': 30, 'dropout': 0.2, 'batch_size': 8, 'learn_rate': 0.001, 'early_stopping_patience': 5, 'min_improvement': 0.001}\n"
     ]
    }
   ],
   "source": [
    "# Data paths\n",
    "DATA_ROOT = Path(\"../data\")\n",
    "INPUT_DATA_PATH = DATA_ROOT / \"ner_data\" / \"spacy_ner_data.json\"\n",
    "MODELS_DIR = DATA_ROOT / \"models\"\n",
    "MODELS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Training configuration\n",
    "CONFIG = {\n",
    "    'train_split': 0.7,\n",
    "    'val_split': 0.15,\n",
    "    'test_split': 0.15,\n",
    "    'n_iter': 30,\n",
    "    'dropout': 0.2,\n",
    "    'batch_size': 8,\n",
    "    'learn_rate': 0.001,\n",
    "    'early_stopping_patience': 5,\n",
    "    'min_improvement': 0.001\n",
    "}\n",
    "\n",
    "print(f\"Training data path: {INPUT_DATA_PATH}\")\n",
    "print(f\"Models directory: {MODELS_DIR}\")\n",
    "print(f\"Configuration: {CONFIG}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Loaded 3283 raw examples\n",
      "After validation: 3283 valid examples\n",
      "Total entities: 6065\n",
      "Label distribution: {'ASTRO_OBJ': 6065}\n"
     ]
    }
   ],
   "source": [
    "def load_training_data(data_path: Path) -> List[Tuple[str, Dict]]:\n",
    "    \"\"\"Load spaCy training data from JSON file.\n",
    "    \n",
    "    Args:\n",
    "        data_path: Path to the JSON file containing training data\n",
    "        \n",
    "    Returns:\n",
    "        List of (text, annotations) tuples in spaCy format\n",
    "    \"\"\"\n",
    "    with open(data_path, 'r', encoding='utf-8') as f:\n",
    "        raw_data = json.load(f)\n",
    "    \n",
    "    training_examples = []\n",
    "    \n",
    "    for doc_data in raw_data:\n",
    "        spacy_data = doc_data.get('spacy_ner_data', [])\n",
    "        \n",
    "        # spacy_ner_data contains alternating text and annotation dictionaries\n",
    "        for i in range(0, len(spacy_data), 2):\n",
    "            if i + 1 < len(spacy_data):\n",
    "                text = spacy_data[i]\n",
    "                annotations = spacy_data[i + 1]\n",
    "                if isinstance(text, str) and isinstance(annotations, dict):\n",
    "                    training_examples.append((text, annotations))\n",
    "    \n",
    "    return training_examples\n",
    "\n",
    "def validate_training_data(training_data: List[Tuple[str, Dict]]) -> List[Tuple[str, Dict]]:\n",
    "    \"\"\"Validate and clean training data.\n",
    "    \n",
    "    Args:\n",
    "        training_data: List of (text, annotations) tuples\n",
    "        \n",
    "    Returns:\n",
    "        Cleaned list of valid training examples\n",
    "    \"\"\"\n",
    "    valid_examples = []\n",
    "    \n",
    "    for text, annotations in training_data:\n",
    "        if not text or not isinstance(text, str):\n",
    "            continue\n",
    "            \n",
    "        entities = annotations.get('entities', [])\n",
    "        valid_entities = []\n",
    "        \n",
    "        for entity in entities:\n",
    "            if len(entity) == 3:\n",
    "                start, end, label = entity\n",
    "                # Validate entity boundaries\n",
    "                if 0 <= start < end <= len(text):\n",
    "                    valid_entities.append((start, end, label))\n",
    "        \n",
    "        if valid_entities:  # Only keep examples with valid entities\n",
    "            valid_examples.append((text, {'entities': valid_entities}))\n",
    "    \n",
    "    return valid_examples\n",
    "\n",
    "# Load and validate data\n",
    "print(\"Loading training data...\")\n",
    "raw_training_data = load_training_data(INPUT_DATA_PATH)\n",
    "training_data = validate_training_data(raw_training_data)\n",
    "\n",
    "print(f\"Loaded {len(raw_training_data)} raw examples\")\n",
    "print(f\"After validation: {len(training_data)} valid examples\")\n",
    "\n",
    "# Data statistics\n",
    "total_entities = sum(len(annotations['entities']) for _, annotations in training_data)\n",
    "entity_labels = [label for _, annotations in training_data \n",
    "                for _, _, label in annotations['entities']]\n",
    "label_counts = Counter(entity_labels)\n",
    "\n",
    "print(f\"Total entities: {total_entities}\")\n",
    "print(f\"Label distribution: {dict(label_counts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating train/validation/test splits...\n",
      "\n",
      "Train Set:\n",
      "  Examples: 2297\n",
      "  Total entities: 4206\n",
      "  Avg entities per example: 1.83\n",
      "  Label distribution: {'ASTRO_OBJ': 4206}\n",
      "\n",
      "Validation Set:\n",
      "  Examples: 493\n",
      "  Total entities: 946\n",
      "  Avg entities per example: 1.92\n",
      "  Label distribution: {'ASTRO_OBJ': 946}\n",
      "\n",
      "Test Set:\n",
      "  Examples: 493\n",
      "  Total entities: 913\n",
      "  Avg entities per example: 1.85\n",
      "  Label distribution: {'ASTRO_OBJ': 913}\n"
     ]
    }
   ],
   "source": [
    "def create_stratified_split(training_data: List[Tuple[str, Dict]], \n",
    "                          train_ratio: float = 0.7, \n",
    "                          val_ratio: float = 0.15, \n",
    "                          test_ratio: float = 0.15) -> Tuple[List, List, List]:\n",
    "    \"\"\"Create stratified train/validation/test splits.\n",
    "    \n",
    "    Args:\n",
    "        training_data: List of (text, annotations) tuples\n",
    "        train_ratio: Proportion for training set\n",
    "        val_ratio: Proportion for validation set\n",
    "        test_ratio: Proportion for test set\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (train_data, val_data, test_data)\n",
    "    \"\"\"\n",
    "    # Create stratification key based on number of entities and entity types\n",
    "    stratify_keys = []\n",
    "    for text, annotations in training_data:\n",
    "        entities = annotations['entities']\n",
    "        num_entities = len(entities)\n",
    "        unique_labels = set(label for _, _, label in entities)\n",
    "        # Create a key that considers both count and variety of entities\n",
    "        key = f\"{min(num_entities, 5)}_{len(unique_labels)}\"  # Cap at 5 for grouping\n",
    "        stratify_keys.append(key)\n",
    "    \n",
    "    # First split: separate test set\n",
    "    train_val_data, test_data, train_val_keys, _ = train_test_split(\n",
    "        training_data, stratify_keys, \n",
    "        test_size=test_ratio, \n",
    "        random_state=42, \n",
    "        stratify=stratify_keys\n",
    "    )\n",
    "    \n",
    "    # Second split: separate train and validation\n",
    "    val_size = val_ratio / (train_ratio + val_ratio)\n",
    "    train_data, val_data = train_test_split(\n",
    "        train_val_data, \n",
    "        test_size=val_size, \n",
    "        random_state=42, \n",
    "        stratify=train_val_keys\n",
    "    )\n",
    "    \n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "def print_split_statistics(train_data, val_data, test_data):\n",
    "    \"\"\"Print statistics for each data split.\"\"\"\n",
    "    splits = {'Train': train_data, 'Validation': val_data, 'Test': test_data}\n",
    "    \n",
    "    for split_name, data in splits.items():\n",
    "        total_entities = sum(len(annotations['entities']) for _, annotations in data)\n",
    "        entity_labels = [label for _, annotations in data \n",
    "                        for _, _, label in annotations['entities']]\n",
    "        label_counts = Counter(entity_labels)\n",
    "        \n",
    "        print(f\"\\n{split_name} Set:\")\n",
    "        print(f\"  Examples: {len(data)}\")\n",
    "        print(f\"  Total entities: {total_entities}\")\n",
    "        print(f\"  Avg entities per example: {total_entities/len(data):.2f}\")\n",
    "        print(f\"  Label distribution: {dict(label_counts)}\")\n",
    "\n",
    "# Create splits\n",
    "print(\"Creating train/validation/test splits...\")\n",
    "train_data, val_data, test_data = create_stratified_split(\n",
    "    training_data, \n",
    "    CONFIG['train_split'], \n",
    "    CONFIG['val_split'], \n",
    "    CONFIG['test_split']\n",
    ")\n",
    "\n",
    "print_split_statistics(train_data, val_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training Infrastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity labels to train: ['ASTRO_OBJ']\n"
     ]
    }
   ],
   "source": [
    "def create_blank_model(labels: List[str]) -> spacy.Language:\n",
    "    \"\"\"Create a blank spaCy model with NER component.\n",
    "    \n",
    "    Args:\n",
    "        labels: List of entity labels to recognize\n",
    "        \n",
    "    Returns:\n",
    "        Blank spaCy model with NER component\n",
    "    \"\"\"\n",
    "    nlp = English()\n",
    "    \n",
    "    # Create NER component\n",
    "    ner = nlp.add_pipe(\"ner\")\n",
    "    \n",
    "    # Add labels to NER component\n",
    "    for label in labels:\n",
    "        ner.add_label(label)\n",
    "    \n",
    "    return nlp\n",
    "\n",
    "def convert_to_examples(nlp: spacy.Language, \n",
    "                       training_data: List[Tuple[str, Dict]]) -> List[Example]:\n",
    "    \"\"\"Convert training data to spaCy Example objects.\n",
    "    \n",
    "    Args:\n",
    "        nlp: spaCy model\n",
    "        training_data: List of (text, annotations) tuples\n",
    "        \n",
    "    Returns:\n",
    "        List of spaCy Example objects\n",
    "    \"\"\"\n",
    "    examples = []\n",
    "    for text, annotations in training_data:\n",
    "        doc = nlp.make_doc(text)\n",
    "        example = Example.from_dict(doc, annotations)\n",
    "        examples.append(example)\n",
    "    return examples\n",
    "\n",
    "def evaluate_model(nlp: spacy.Language, examples: List[Example]) -> Dict[str, float]:\n",
    "    \"\"\"Evaluate model performance on a set of examples.\n",
    "    \n",
    "    Args:\n",
    "        nlp: Trained spaCy model\n",
    "        examples: List of evaluation examples\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of evaluation metrics\n",
    "    \"\"\"\n",
    "    scores = nlp.evaluate(examples)\n",
    "    return {\n",
    "        'precision': scores['ents_p'],\n",
    "        'recall': scores['ents_r'],\n",
    "        'f1': scores['ents_f'],\n",
    "        'accuracy': scores.get('token_acc', 0.0)\n",
    "    }\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stopping utility for training.\"\"\"\n",
    "    \n",
    "    def __init__(self, patience: int = 5, min_improvement: float = 0.001):\n",
    "        self.patience = patience\n",
    "        self.min_improvement = min_improvement\n",
    "        self.best_score = 0.0\n",
    "        self.wait = 0\n",
    "        self.stopped = False\n",
    "    \n",
    "    def __call__(self, score: float) -> bool:\n",
    "        \"\"\"Check if training should stop.\n",
    "        \n",
    "        Args:\n",
    "            score: Current validation score\n",
    "            \n",
    "        Returns:\n",
    "            True if training should stop\n",
    "        \"\"\"\n",
    "        if score > self.best_score + self.min_improvement:\n",
    "            self.best_score = score\n",
    "            self.wait = 0\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                self.stopped = True\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "# Get unique labels from training data\n",
    "all_labels = set()\n",
    "for _, annotations in training_data:\n",
    "    for _, _, label in annotations['entities']:\n",
    "        all_labels.add(label)\n",
    "\n",
    "print(f\"Entity labels to train: {list(all_labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Function with Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training baseline model...\n",
      "Training model with config: {'train_split': 0.7, 'val_split': 0.15, 'test_split': 0.15, 'n_iter': 30, 'dropout': 0.2, 'batch_size': 8, 'learn_rate': 0.001, 'early_stopping_patience': 5, 'min_improvement': 0.001}\n",
      "\n",
      "Starting training...\n",
      "Epoch | Train Loss | Val F1  | Val Prec | Val Rec\n",
      "--------------------------------------------------\n",
      "    1 |  3609.8643 |   0.000 |    0.000 |   0.000\n",
      "    2 |    80.6002 |   0.000 |    0.000 |   0.000\n",
      "    3 |    69.4667 |   1.000 |    1.000 |   1.000\n",
      "    4 |    59.0282 |   1.000 |    1.000 |   1.000\n",
      "    5 |    52.4558 |   1.000 |    1.000 |   1.000\n",
      "    6 |    32.8050 |   1.000 |    1.000 |   1.000\n",
      "    7 |    31.8141 |   0.800 |    0.667 |   1.000\n",
      "    8 |    25.6744 |   1.000 |    1.000 |   1.000\n",
      "\n",
      "Early stopping at epoch 8\n"
     ]
    }
   ],
   "source": [
    "def train_ner_model(train_data: List[Tuple[str, Dict]], \n",
    "                   val_data: List[Tuple[str, Dict]],\n",
    "                   labels: List[str],\n",
    "                   config: Dict[str, Any]) -> Tuple[spacy.Language, Dict[str, List[float]]]:\n",
    "    \"\"\"Train a spaCy NER model with the given configuration.\n",
    "    \n",
    "    Args:\n",
    "        train_data: Training data\n",
    "        val_data: Validation data\n",
    "        labels: Entity labels\n",
    "        config: Training configuration\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (trained_model, training_history)\n",
    "    \"\"\"\n",
    "    print(f\"Training model with config: {config}\")\n",
    "    \n",
    "    # Create model\n",
    "    nlp = create_blank_model(labels)\n",
    "    \n",
    "    # Convert to examples\n",
    "    train_examples = convert_to_examples(nlp, train_data)\n",
    "    val_examples = convert_to_examples(nlp, val_data)\n",
    "    \n",
    "    # Initialize training\n",
    "    nlp.initialize(lambda: train_examples)\n",
    "    \n",
    "    # Training history\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'val_f1': [],\n",
    "        'val_precision': [],\n",
    "        'val_recall': []\n",
    "    }\n",
    "    \n",
    "    # Early stopping\n",
    "    early_stopping = EarlyStopping(\n",
    "        patience=config['early_stopping_patience'],\n",
    "        min_improvement=config['min_improvement']\n",
    "    )\n",
    "    \n",
    "    print(\"\\nStarting training...\")\n",
    "    print(\"Epoch | Train Loss | Val F1  | Val Prec | Val Rec\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for epoch in range(config['n_iter']):\n",
    "        # Shuffle training data\n",
    "        random.shuffle(train_examples)\n",
    "        \n",
    "        # Training\n",
    "        losses = {}\n",
    "        batches = minibatch(train_examples, size=compounding(4.0, 32.0, 1.001))\n",
    "        \n",
    "        for batch in batches:\n",
    "            nlp.update(\n",
    "                batch,\n",
    "                drop=config['dropout'],\n",
    "                losses=losses,\n",
    "                sgd=nlp.create_optimizer()\n",
    "            )\n",
    "        \n",
    "        # Validation\n",
    "        val_scores = evaluate_model(nlp, val_examples)\n",
    "        \n",
    "        # Record history\n",
    "        history['train_loss'].append(losses.get('ner', 0.0))\n",
    "        history['val_f1'].append(val_scores['f1'])\n",
    "        history['val_precision'].append(val_scores['precision'])\n",
    "        history['val_recall'].append(val_scores['recall'])\n",
    "        \n",
    "        # Print progress\n",
    "        print(f\"{epoch+1:5d} | {losses.get('ner', 0.0):10.4f} | \"\n",
    "              f\"{val_scores['f1']:7.3f} | {val_scores['precision']:8.3f} | \"\n",
    "              f\"{val_scores['recall']:7.3f}\")\n",
    "        \n",
    "        # Early stopping check\n",
    "        if early_stopping(val_scores['f1']):\n",
    "            print(f\"\\nEarly stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    return nlp, history\n",
    "\n",
    "# Train baseline model\n",
    "print(\"Training baseline model...\")\n",
    "baseline_model, baseline_history = train_ner_model(\n",
    "    train_data, val_data, list(all_labels), CONFIG\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "HYPERPARAMETER OPTIMIZATION\n",
      "============================================================\n",
      "Starting hyperparameter search...\n",
      "Testing 48 combinations\n",
      "\n",
      "--- Experiment 1 ---\n",
      "Dropout: 0.1, LR: 0.0005, Iterations: 20\n",
      "Training model with config: {'train_split': 0.7, 'val_split': 0.15, 'test_split': 0.15, 'n_iter': 20, 'dropout': 0.1, 'batch_size': 8, 'learn_rate': 0.0005, 'early_stopping_patience': 3, 'min_improvement': 0.001}\n",
      "\n",
      "Starting training...\n",
      "Epoch | Train Loss | Val F1  | Val Prec | Val Rec\n",
      "--------------------------------------------------\n",
      "    1 |  4202.0308 |   0.000 |    0.000 |   0.000\n",
      "    2 |     4.3548 |   0.000 |    0.000 |   0.000\n",
      "    3 |     4.0000 |   0.000 |    0.000 |   0.000\n",
      "\n",
      "Early stopping at epoch 3\n",
      "Final F1: 0.0000\n",
      "\n",
      "--- Experiment 2 ---\n",
      "Dropout: 0.1, LR: 0.0005, Iterations: 30\n",
      "Training model with config: {'train_split': 0.7, 'val_split': 0.15, 'test_split': 0.15, 'n_iter': 30, 'dropout': 0.1, 'batch_size': 8, 'learn_rate': 0.0005, 'early_stopping_patience': 3, 'min_improvement': 0.001}\n",
      "\n",
      "Starting training...\n",
      "Epoch | Train Loss | Val F1  | Val Prec | Val Rec\n",
      "--------------------------------------------------\n",
      "    1 |  3828.1055 |   0.000 |    0.000 |   0.000\n",
      "    2 |     7.3883 |   0.000 |    0.000 |   0.000\n",
      "    3 |     4.0016 |   0.000 |    0.000 |   0.000\n",
      "\n",
      "Early stopping at epoch 3\n",
      "Final F1: 0.0000\n",
      "\n",
      "--- Experiment 3 ---\n",
      "Dropout: 0.1, LR: 0.0005, Iterations: 40\n",
      "Training model with config: {'train_split': 0.7, 'val_split': 0.15, 'test_split': 0.15, 'n_iter': 40, 'dropout': 0.1, 'batch_size': 8, 'learn_rate': 0.0005, 'early_stopping_patience': 3, 'min_improvement': 0.001}\n",
      "\n",
      "Starting training...\n",
      "Epoch | Train Loss | Val F1  | Val Prec | Val Rec\n",
      "--------------------------------------------------\n",
      "    1 |  3919.6182 |   0.000 |    0.000 |   0.000\n",
      "    2 |     4.0509 |   0.000 |    0.000 |   0.000\n",
      "    3 |     4.1206 |   0.000 |    0.000 |   0.000\n",
      "\n",
      "Early stopping at epoch 3\n",
      "Final F1: 0.0000\n",
      "\n",
      "--- Experiment 4 ---\n",
      "Dropout: 0.1, LR: 0.001, Iterations: 20\n",
      "Training model with config: {'train_split': 0.7, 'val_split': 0.15, 'test_split': 0.15, 'n_iter': 20, 'dropout': 0.1, 'batch_size': 8, 'learn_rate': 0.001, 'early_stopping_patience': 3, 'min_improvement': 0.001}\n",
      "\n",
      "Starting training...\n",
      "Epoch | Train Loss | Val F1  | Val Prec | Val Rec\n",
      "--------------------------------------------------\n",
      "    1 |  3547.1306 |   0.000 |    0.000 |   0.000\n",
      "    2 |     4.0058 |   0.000 |    0.000 |   0.000\n",
      "    3 |     4.2737 |   0.000 |    0.000 |   0.000\n",
      "\n",
      "Early stopping at epoch 3\n",
      "Final F1: 0.0000\n",
      "\n",
      "--- Experiment 5 ---\n",
      "Dropout: 0.1, LR: 0.001, Iterations: 30\n",
      "Training model with config: {'train_split': 0.7, 'val_split': 0.15, 'test_split': 0.15, 'n_iter': 30, 'dropout': 0.1, 'batch_size': 8, 'learn_rate': 0.001, 'early_stopping_patience': 3, 'min_improvement': 0.001}\n",
      "\n",
      "Starting training...\n",
      "Epoch | Train Loss | Val F1  | Val Prec | Val Rec\n",
      "--------------------------------------------------\n",
      "    1 |  3846.1118 |   0.000 |    0.000 |   0.000\n",
      "    2 |     6.2774 |   0.000 |    0.000 |   0.000\n",
      "    3 |     4.0124 |   0.000 |    0.000 |   0.000\n",
      "\n",
      "Early stopping at epoch 3\n",
      "Final F1: 0.0000\n",
      "\n",
      "--- Experiment 6 ---\n",
      "Dropout: 0.1, LR: 0.001, Iterations: 40\n",
      "Training model with config: {'train_split': 0.7, 'val_split': 0.15, 'test_split': 0.15, 'n_iter': 40, 'dropout': 0.1, 'batch_size': 8, 'learn_rate': 0.001, 'early_stopping_patience': 3, 'min_improvement': 0.001}\n",
      "\n",
      "Starting training...\n",
      "Epoch | Train Loss | Val F1  | Val Prec | Val Rec\n",
      "--------------------------------------------------\n",
      "    1 |  4293.7925 |   0.000 |    0.000 |   0.000\n",
      "    2 |     7.1388 |   0.000 |    0.000 |   0.000\n",
      "    3 |     4.0644 |   0.000 |    0.000 |   0.000\n",
      "\n",
      "Early stopping at epoch 3\n",
      "Final F1: 0.0000\n",
      "\n",
      "--- Experiment 7 ---\n",
      "Dropout: 0.1, LR: 0.002, Iterations: 20\n",
      "Training model with config: {'train_split': 0.7, 'val_split': 0.15, 'test_split': 0.15, 'n_iter': 20, 'dropout': 0.1, 'batch_size': 8, 'learn_rate': 0.002, 'early_stopping_patience': 3, 'min_improvement': 0.001}\n",
      "\n",
      "Starting training...\n",
      "Epoch | Train Loss | Val F1  | Val Prec | Val Rec\n",
      "--------------------------------------------------\n",
      "    1 |  3702.4238 |   0.000 |    0.000 |   0.000\n",
      "    2 |     5.0914 |   0.000 |    0.000 |   0.000\n",
      "    3 |     4.0114 |   0.000 |    0.000 |   0.000\n",
      "\n",
      "Early stopping at epoch 3\n",
      "Final F1: 0.0000\n",
      "\n",
      "--- Experiment 8 ---\n",
      "Dropout: 0.1, LR: 0.002, Iterations: 30\n",
      "Training model with config: {'train_split': 0.7, 'val_split': 0.15, 'test_split': 0.15, 'n_iter': 30, 'dropout': 0.1, 'batch_size': 8, 'learn_rate': 0.002, 'early_stopping_patience': 3, 'min_improvement': 0.001}\n",
      "\n",
      "Starting training...\n",
      "Epoch | Train Loss | Val F1  | Val Prec | Val Rec\n",
      "--------------------------------------------------\n",
      "    1 |  4202.9624 |   0.000 |    0.000 |   0.000\n",
      "    2 |     4.6828 |   0.000 |    0.000 |   0.000\n",
      "    3 |     4.0216 |   0.000 |    0.000 |   0.000\n",
      "\n",
      "Early stopping at epoch 3\n",
      "Final F1: 0.0000\n",
      "\n",
      "--- Experiment 9 ---\n",
      "Dropout: 0.1, LR: 0.002, Iterations: 40\n",
      "Training model with config: {'train_split': 0.7, 'val_split': 0.15, 'test_split': 0.15, 'n_iter': 40, 'dropout': 0.1, 'batch_size': 8, 'learn_rate': 0.002, 'early_stopping_patience': 3, 'min_improvement': 0.001}\n",
      "\n",
      "Starting training...\n",
      "Epoch | Train Loss | Val F1  | Val Prec | Val Rec\n",
      "--------------------------------------------------\n",
      "    1 |  5223.5938 |   0.000 |    0.000 |   0.000\n",
      "    2 |     8.2166 |   0.000 |    0.000 |   0.000\n",
      "    3 |     4.0000 |   0.000 |    0.000 |   0.000\n",
      "\n",
      "Early stopping at epoch 3\n",
      "Final F1: 0.0000\n",
      "\n",
      "--- Experiment 10 ---\n",
      "Dropout: 0.1, LR: 0.005, Iterations: 20\n",
      "Training model with config: {'train_split': 0.7, 'val_split': 0.15, 'test_split': 0.15, 'n_iter': 20, 'dropout': 0.1, 'batch_size': 8, 'learn_rate': 0.005, 'early_stopping_patience': 3, 'min_improvement': 0.001}\n",
      "\n",
      "Starting training...\n",
      "Epoch | Train Loss | Val F1  | Val Prec | Val Rec\n",
      "--------------------------------------------------\n",
      "    1 |  4256.1855 |   0.000 |    0.000 |   0.000\n",
      "    2 |     6.8542 |   0.000 |    0.000 |   0.000\n",
      "    3 |     4.5000 |   0.000 |    0.000 |   0.000\n",
      "\n",
      "Early stopping at epoch 3\n",
      "Final F1: 0.0000\n",
      "\n",
      "--- Experiment 11 ---\n",
      "Dropout: 0.1, LR: 0.005, Iterations: 30\n",
      "Training model with config: {'train_split': 0.7, 'val_split': 0.15, 'test_split': 0.15, 'n_iter': 30, 'dropout': 0.1, 'batch_size': 8, 'learn_rate': 0.005, 'early_stopping_patience': 3, 'min_improvement': 0.001}\n",
      "\n",
      "Starting training...\n",
      "Epoch | Train Loss | Val F1  | Val Prec | Val Rec\n",
      "--------------------------------------------------\n",
      "    1 |  4653.6553 |   0.000 |    0.000 |   0.000\n",
      "    2 |     4.0449 |   0.000 |    0.000 |   0.000\n",
      "    3 |     4.4795 |   0.000 |    0.000 |   0.000\n",
      "\n",
      "Early stopping at epoch 3\n",
      "Final F1: 0.0000\n",
      "\n",
      "--- Experiment 12 ---\n",
      "Dropout: 0.1, LR: 0.005, Iterations: 40\n",
      "Training model with config: {'train_split': 0.7, 'val_split': 0.15, 'test_split': 0.15, 'n_iter': 40, 'dropout': 0.1, 'batch_size': 8, 'learn_rate': 0.005, 'early_stopping_patience': 3, 'min_improvement': 0.001}\n",
      "\n",
      "Starting training...\n",
      "Epoch | Train Loss | Val F1  | Val Prec | Val Rec\n",
      "--------------------------------------------------\n",
      "    1 |  4196.2178 |   0.000 |    0.000 |   0.000\n",
      "    2 |    15.0094 |   0.000 |    0.000 |   0.000\n",
      "    3 |     4.0000 |   0.000 |    0.000 |   0.000\n",
      "\n",
      "Early stopping at epoch 3\n",
      "Final F1: 0.0000\n",
      "\n",
      "--- Experiment 13 ---\n",
      "Dropout: 0.2, LR: 0.0005, Iterations: 20\n",
      "Training model with config: {'train_split': 0.7, 'val_split': 0.15, 'test_split': 0.15, 'n_iter': 20, 'dropout': 0.2, 'batch_size': 8, 'learn_rate': 0.0005, 'early_stopping_patience': 3, 'min_improvement': 0.001}\n",
      "\n",
      "Starting training...\n",
      "Epoch | Train Loss | Val F1  | Val Prec | Val Rec\n",
      "--------------------------------------------------\n",
      "    1 |  3992.3181 |   0.000 |    0.000 |   0.000\n",
      "    2 |     4.4471 |   0.000 |    0.000 |   0.000\n",
      "    3 |     4.0000 |   0.000 |    0.000 |   0.000\n",
      "\n",
      "Early stopping at epoch 3\n",
      "Final F1: 0.0000\n",
      "\n",
      "--- Experiment 14 ---\n",
      "Dropout: 0.2, LR: 0.0005, Iterations: 30\n",
      "Training model with config: {'train_split': 0.7, 'val_split': 0.15, 'test_split': 0.15, 'n_iter': 30, 'dropout': 0.2, 'batch_size': 8, 'learn_rate': 0.0005, 'early_stopping_patience': 3, 'min_improvement': 0.001}\n",
      "\n",
      "Starting training...\n",
      "Epoch | Train Loss | Val F1  | Val Prec | Val Rec\n",
      "--------------------------------------------------\n",
      "    1 |  3984.9817 |   0.000 |    0.000 |   0.000\n",
      "    2 |     4.5391 |   0.000 |    0.000 |   0.000\n",
      "    3 |     4.0000 |   0.000 |    0.000 |   0.000\n",
      "\n",
      "Early stopping at epoch 3\n",
      "Final F1: 0.0000\n",
      "\n",
      "--- Experiment 15 ---\n",
      "Dropout: 0.2, LR: 0.0005, Iterations: 40\n",
      "Training model with config: {'train_split': 0.7, 'val_split': 0.15, 'test_split': 0.15, 'n_iter': 40, 'dropout': 0.2, 'batch_size': 8, 'learn_rate': 0.0005, 'early_stopping_patience': 3, 'min_improvement': 0.001}\n",
      "\n",
      "Starting training...\n",
      "Epoch | Train Loss | Val F1  | Val Prec | Val Rec\n",
      "--------------------------------------------------\n",
      "    1 |  4271.4155 |   0.000 |    0.000 |   0.000\n",
      "    2 |    12.7743 |   0.000 |    0.000 |   0.000\n",
      "    3 |     4.0117 |   0.000 |    0.000 |   0.000\n",
      "\n",
      "Early stopping at epoch 3\n",
      "Final F1: 0.0000\n",
      "\n",
      "--- Experiment 16 ---\n",
      "Dropout: 0.2, LR: 0.001, Iterations: 20\n",
      "Training model with config: {'train_split': 0.7, 'val_split': 0.15, 'test_split': 0.15, 'n_iter': 20, 'dropout': 0.2, 'batch_size': 8, 'learn_rate': 0.001, 'early_stopping_patience': 3, 'min_improvement': 0.001}\n",
      "\n",
      "Starting training...\n",
      "Epoch | Train Loss | Val F1  | Val Prec | Val Rec\n",
      "--------------------------------------------------\n",
      "    1 |  4735.0327 |   0.000 |    0.000 |   0.000\n",
      "    2 |    10.2385 |   0.000 |    0.000 |   0.000\n",
      "    3 |     4.0001 |   0.000 |    0.000 |   0.000\n",
      "\n",
      "Early stopping at epoch 3\n",
      "Final F1: 0.0000\n",
      "\n",
      "--- Experiment 17 ---\n",
      "Dropout: 0.2, LR: 0.001, Iterations: 30\n",
      "Training model with config: {'train_split': 0.7, 'val_split': 0.15, 'test_split': 0.15, 'n_iter': 30, 'dropout': 0.2, 'batch_size': 8, 'learn_rate': 0.001, 'early_stopping_patience': 3, 'min_improvement': 0.001}\n",
      "\n",
      "Starting training...\n",
      "Epoch | Train Loss | Val F1  | Val Prec | Val Rec\n",
      "--------------------------------------------------\n",
      "    1 |  3746.0967 |   0.000 |    0.000 |   0.000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 92\u001b[39m\n\u001b[32m     86\u001b[39m search_config = CONFIG.copy()\n\u001b[32m     87\u001b[39m search_config.update({\n\u001b[32m     88\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mearly_stopping_patience\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m3\u001b[39m,  \u001b[38;5;66;03m# Faster for search\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mn_iter\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m15\u001b[39m  \u001b[38;5;66;03m# Will be overridden in search\u001b[39;00m\n\u001b[32m     90\u001b[39m })\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m best_config, best_scores, search_results = \u001b[43mhyperparameter_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Use subset for faster search\u001b[39;49;00m\n\u001b[32m     94\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mall_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m    \u001b[49m\u001b[43msearch_config\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m=\u001b[39m\u001b[33m'\u001b[39m*\u001b[32m60\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    100\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBEST CONFIGURATION FOUND:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 51\u001b[39m, in \u001b[36mhyperparameter_search\u001b[39m\u001b[34m(train_data, val_data, labels, base_config)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDropout: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdropout\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, LR: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlearn_rate\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Iterations: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_iter\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     50\u001b[39m     \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     model, history = \u001b[43mtrain_ner_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m     \u001b[38;5;66;03m# Final validation score\u001b[39;00m\n\u001b[32m     54\u001b[39m     val_examples = convert_to_examples(model, val_data)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 55\u001b[39m, in \u001b[36mtrain_ner_model\u001b[39m\u001b[34m(train_data, val_data, labels, config)\u001b[39m\n\u001b[32m     52\u001b[39m batches = minibatch(train_examples, size=compounding(\u001b[32m4.0\u001b[39m, \u001b[32m32.0\u001b[39m, \u001b[32m1.001\u001b[39m))\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m batches:\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m     \u001b[43mnlp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdropout\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlosses\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlosses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m        \u001b[49m\u001b[43msgd\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnlp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_optimizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# Validation\u001b[39;00m\n\u001b[32m     63\u001b[39m val_scores = evaluate_model(nlp, val_examples)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/astronomical-ner/.venv/lib/python3.12/site-packages/spacy/language.py:1197\u001b[39m, in \u001b[36mLanguage.update\u001b[39m\u001b[34m(self, examples, _, drop, sgd, losses, component_cfg, exclude, annotates)\u001b[39m\n\u001b[32m   1194\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, proc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pipeline:\n\u001b[32m   1195\u001b[39m     \u001b[38;5;66;03m# ignore statements are used here because mypy ignores hasattr\u001b[39;00m\n\u001b[32m   1196\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m exclude \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(proc, \u001b[33m\"\u001b[39m\u001b[33mupdate\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1197\u001b[39m         \u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msgd\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlosses\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlosses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcomponent_cfg\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m   1198\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m sgd \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m   1199\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   1200\u001b[39m             name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m exclude\n\u001b[32m   1201\u001b[39m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(proc, ty.TrainableComponent)\n\u001b[32m   1202\u001b[39m             \u001b[38;5;129;01mand\u001b[39;00m proc.is_trainable\n\u001b[32m   1203\u001b[39m             \u001b[38;5;129;01mand\u001b[39;00m proc.model \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m   1204\u001b[39m         ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/astronomical-ner/.venv/lib/python3.12/site-packages/spacy/pipeline/transition_parser.pyx:439\u001b[39m, in \u001b[36mspacy.pipeline.transition_parser.Parser.update\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/astronomical-ner/.venv/lib/python3.12/site-packages/spacy/ml/parser_model.pyx:334\u001b[39m, in \u001b[36mspacy.ml.parser_model.ParserStepModel.finish_steps\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/astronomical-ner/.venv/lib/python3.12/site-packages/thinc/layers/chain.py:60\u001b[39m, in \u001b[36mforward.<locals>.backprop\u001b[39m\u001b[34m(dY)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbackprop\u001b[39m(dY: OutT) -> InT:\n\u001b[32m     59\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(callbacks):\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m         dX = \u001b[43mcallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m         dY = dX\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m dX\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/astronomical-ner/.venv/lib/python3.12/site-packages/thinc/layers/chain.py:60\u001b[39m, in \u001b[36mforward.<locals>.backprop\u001b[39m\u001b[34m(dY)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbackprop\u001b[39m(dY: OutT) -> InT:\n\u001b[32m     59\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(callbacks):\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m         dX = \u001b[43mcallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m         dY = dX\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m dX\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/astronomical-ner/.venv/lib/python3.12/site-packages/thinc/layers/with_array.py:81\u001b[39m, in \u001b[36m_list_forward.<locals>.backprop\u001b[39m\u001b[34m(dYs)\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbackprop\u001b[39m(dYs: ListXd) -> ListXd:\n\u001b[32m     80\u001b[39m     dYf = layer.ops.flatten(dYs, pad=pad)\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     dXf = \u001b[43mget_dXf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdYf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m layer.ops.unflatten(dXf, lengths, pad=pad)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/astronomical-ner/.venv/lib/python3.12/site-packages/thinc/layers/chain.py:60\u001b[39m, in \u001b[36mforward.<locals>.backprop\u001b[39m\u001b[34m(dY)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbackprop\u001b[39m(dY: OutT) -> InT:\n\u001b[32m     59\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(callbacks):\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m         dX = \u001b[43mcallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m         dY = dX\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m dX\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/astronomical-ner/.venv/lib/python3.12/site-packages/thinc/layers/residual.py:30\u001b[39m, in \u001b[36mforward.<locals>.backprop\u001b[39m\u001b[34m(d_output)\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbackprop\u001b[39m(d_output: InT) -> InT:\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     dX = \u001b[43mbackprop_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(d_output, \u001b[38;5;28mlist\u001b[39m):\n\u001b[32m     32\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m [d_output[i] + dX[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(d_output))]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/astronomical-ner/.venv/lib/python3.12/site-packages/thinc/layers/chain.py:60\u001b[39m, in \u001b[36mforward.<locals>.backprop\u001b[39m\u001b[34m(dY)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbackprop\u001b[39m(dY: OutT) -> InT:\n\u001b[32m     59\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(callbacks):\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m         dX = \u001b[43mcallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m         dY = dX\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m dX\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/astronomical-ner/.venv/lib/python3.12/site-packages/thinc/layers/chain.py:60\u001b[39m, in \u001b[36mforward.<locals>.backprop\u001b[39m\u001b[34m(dY)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbackprop\u001b[39m(dY: OutT) -> InT:\n\u001b[32m     59\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(callbacks):\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m         dX = \u001b[43mcallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m         dY = dX\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m dX\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/astronomical-ner/.venv/lib/python3.12/site-packages/thinc/layers/chain.py:60\u001b[39m, in \u001b[36mforward.<locals>.backprop\u001b[39m\u001b[34m(dY)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbackprop\u001b[39m(dY: OutT) -> InT:\n\u001b[32m     59\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(callbacks):\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m         dX = \u001b[43mcallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m         dY = dX\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m dX\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/astronomical-ner/.venv/lib/python3.12/site-packages/thinc/layers/maxout.py:64\u001b[39m, in \u001b[36mforward.<locals>.backprop\u001b[39m\u001b[34m(d_best)\u001b[39m\n\u001b[32m     62\u001b[39m dW = model.ops.reshape3f(model.ops.gemm(dY, X, trans1=\u001b[38;5;28;01mTrue\u001b[39;00m), nO, nP, nI)\n\u001b[32m     63\u001b[39m model.inc_grad(\u001b[33m\"\u001b[39m\u001b[33mW\u001b[39m\u001b[33m\"\u001b[39m, dW)\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgemm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreshape2f\u001b[49m\u001b[43m(\u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnO\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mnP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnI\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def hyperparameter_search(train_data: List[Tuple[str, Dict]], \n",
    "                         val_data: List[Tuple[str, Dict]],\n",
    "                         labels: List[str],\n",
    "                         base_config: Dict[str, Any]) -> Tuple[Dict, Dict, List[Dict]]:\n",
    "    \"\"\"Perform hyperparameter optimization.\n",
    "    \n",
    "    Args:\n",
    "        train_data: Training data\n",
    "        val_data: Validation data\n",
    "        labels: Entity labels\n",
    "        base_config: Base configuration to modify\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (best_config, best_scores, all_results)\n",
    "    \"\"\"\n",
    "    # Parameter grid\n",
    "    param_grid = {\n",
    "        'dropout': [0.1, 0.2, 0.3, 0.4],\n",
    "        'learn_rate': [0.0005, 0.001, 0.002, 0.005],\n",
    "        'n_iter': [20, 30, 40]\n",
    "    }\n",
    "    \n",
    "    best_f1 = 0.0\n",
    "    best_config = None\n",
    "    best_scores = None\n",
    "    all_results = []\n",
    "    \n",
    "    print(\"Starting hyperparameter search...\")\n",
    "    print(f\"Testing {len(param_grid['dropout']) * len(param_grid['learn_rate']) * len(param_grid['n_iter'])} combinations\")\n",
    "    \n",
    "    experiment_num = 0\n",
    "    \n",
    "    for dropout in param_grid['dropout']:\n",
    "        for learn_rate in param_grid['learn_rate']:\n",
    "            for n_iter in param_grid['n_iter']:\n",
    "                experiment_num += 1\n",
    "                \n",
    "                # Create config for this experiment\n",
    "                current_config = base_config.copy()\n",
    "                current_config.update({\n",
    "                    'dropout': dropout,\n",
    "                    'learn_rate': learn_rate,\n",
    "                    'n_iter': n_iter\n",
    "                })\n",
    "                \n",
    "                print(f\"\\n--- Experiment {experiment_num} ---\")\n",
    "                print(f\"Dropout: {dropout}, LR: {learn_rate}, Iterations: {n_iter}\")\n",
    "                \n",
    "                try:\n",
    "                    # Train model\n",
    "                    model, history = train_ner_model(train_data, val_data, labels, current_config)\n",
    "                    \n",
    "                    # Final validation score\n",
    "                    val_examples = convert_to_examples(model, val_data)\n",
    "                    final_scores = evaluate_model(model, val_examples)\n",
    "                    \n",
    "                    # Record results\n",
    "                    result = {\n",
    "                        'config': current_config.copy(),\n",
    "                        'scores': final_scores,\n",
    "                        'history': history\n",
    "                    }\n",
    "                    all_results.append(result)\n",
    "                    \n",
    "                    print(f\"Final F1: {final_scores['f1']:.4f}\")\n",
    "                    \n",
    "                    # Update best\n",
    "                    if final_scores['f1'] > best_f1:\n",
    "                        best_f1 = final_scores['f1']\n",
    "                        best_config = current_config.copy()\n",
    "                        best_scores = final_scores.copy()\n",
    "                        print(f\"*** New best F1: {best_f1:.4f} ***\")\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"Error in experiment {experiment_num}: {e}\")\n",
    "                    continue\n",
    "    \n",
    "    return best_config, best_scores, all_results\n",
    "\n",
    "# Run hyperparameter search (reduced grid for demo)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"HYPERPARAMETER OPTIMIZATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Use a smaller search space for demonstration\n",
    "search_config = CONFIG.copy()\n",
    "search_config.update({\n",
    "    'early_stopping_patience': 3,  # Faster for search\n",
    "    'n_iter': 15  # Will be overridden in search\n",
    "})\n",
    "\n",
    "best_config, best_scores, search_results = hyperparameter_search(\n",
    "    train_data[:100],  # Use subset for faster search\n",
    "    val_data[:50], \n",
    "    list(all_labels), \n",
    "    search_config\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"BEST CONFIGURATION FOUND:\")\n",
    "print(f\"Config: {best_config}\")\n",
    "print(f\"Scores: {best_scores}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model Training with Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model with best configuration on full dataset\n",
    "print(\"\\nTraining final model with best configuration...\")\n",
    "final_model, final_history = train_ner_model(\n",
    "    train_data, val_data, list(all_labels), best_config\n",
    ")\n",
    "\n",
    "# Save the final model\n",
    "model_path = MODELS_DIR / \"astronomical_ner_model\"\n",
    "final_model.to_disk(model_path)\n",
    "print(f\"\\nModel saved to: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprehensive Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detailed_evaluation(nlp: spacy.Language, \n",
    "                       test_data: List[Tuple[str, Dict]]) -> Dict[str, Any]:\n",
    "    \"\"\"Perform detailed evaluation of the trained model.\n",
    "    \n",
    "    Args:\n",
    "        nlp: Trained spaCy model\n",
    "        test_data: Test dataset\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing detailed evaluation metrics\n",
    "    \"\"\"\n",
    "    test_examples = convert_to_examples(nlp, test_data)\n",
    "    \n",
    "    # Basic metrics\n",
    "    scores = evaluate_model(nlp, test_examples)\n",
    "    \n",
    "    # Entity-level analysis\n",
    "    true_entities = []\n",
    "    pred_entities = []\n",
    "    \n",
    "    for text, annotations in test_data:\n",
    "        doc = nlp(text)\n",
    "        \n",
    "        # True entities\n",
    "        true_ents = [(start, end, label) for start, end, label in annotations['entities']]\n",
    "        true_entities.extend(true_ents)\n",
    "        \n",
    "        # Predicted entities\n",
    "        pred_ents = [(ent.start_char, ent.end_char, ent.label_) for ent in doc.ents]\n",
    "        pred_entities.extend(pred_ents)\n",
    "    \n",
    "    # Error analysis\n",
    "    true_set = set(true_entities)\n",
    "    pred_set = set(pred_entities)\n",
    "    \n",
    "    true_positives = len(true_set & pred_set)\n",
    "    false_positives = len(pred_set - true_set)\n",
    "    false_negatives = len(true_set - pred_set)\n",
    "    \n",
    "    # Calculate metrics manually for verification\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'spacy_scores': scores,\n",
    "        'manual_metrics': {\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1\n",
    "        },\n",
    "        'counts': {\n",
    "            'true_positives': true_positives,\n",
    "            'false_positives': false_positives,\n",
    "            'false_negatives': false_negatives,\n",
    "            'total_true': len(true_entities),\n",
    "            'total_pred': len(pred_entities)\n",
    "        },\n",
    "        'examples': {\n",
    "            'false_positives': list(pred_set - true_set)[:10],\n",
    "            'false_negatives': list(true_set - pred_set)[:10]\n",
    "        }\n",
    "    }\n",
    "\n",
    "def test_model_predictions(nlp: spacy.Language, sample_texts: List[str]):\n",
    "    \"\"\"Test model on sample texts and display predictions.\n",
    "    \n",
    "    Args:\n",
    "        nlp: Trained spaCy model\n",
    "        sample_texts: List of sample texts to test\n",
    "    \"\"\"\n",
    "    print(\"\\nSample Predictions:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for i, text in enumerate(sample_texts, 1):\n",
    "        doc = nlp(text)\n",
    "        print(f\"\\nExample {i}:\")\n",
    "        print(f\"Text: {text}\")\n",
    "        \n",
    "        if doc.ents:\n",
    "            print(\"Predicted entities:\")\n",
    "            for ent in doc.ents:\n",
    "                print(f\"  - '{ent.text}' ({ent.label_}) [{ent.start_char}-{ent.end_char}]\")\n",
    "        else:\n",
    "            print(\"No entities predicted\")\n",
    "\n",
    "# Evaluate final model on test set\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL MODEL EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "evaluation_results = detailed_evaluation(final_model, test_data)\n",
    "\n",
    "print(\"\\nTest Set Performance:\")\n",
    "print(f\"spaCy Precision: {evaluation_results['spacy_scores']['precision']:.4f}\")\n",
    "print(f\"spaCy Recall:    {evaluation_results['spacy_scores']['recall']:.4f}\")\n",
    "print(f\"spaCy F1-Score:  {evaluation_results['spacy_scores']['f1']:.4f}\")\n",
    "\n",
    "print(f\"\\nManual Calculation:\")\n",
    "print(f\"Precision: {evaluation_results['manual_metrics']['precision']:.4f}\")\n",
    "print(f\"Recall:    {evaluation_results['manual_metrics']['recall']:.4f}\")\n",
    "print(f\"F1-Score:  {evaluation_results['manual_metrics']['f1']:.4f}\")\n",
    "\n",
    "print(f\"\\nEntity Counts:\")\n",
    "for key, value in evaluation_results['counts'].items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "print(f\"\\nError Analysis:\")\n",
    "print(f\"Sample False Positives: {evaluation_results['examples']['false_positives'][:5]}\")\n",
    "print(f\"Sample False Negatives: {evaluation_results['examples']['false_negatives'][:5]}\")\n",
    "\n",
    "# Test on sample texts\n",
    "sample_texts = [\n",
    "    \"The Crab Nebula is a supernova remnant located in the constellation Taurus.\",\n",
    "    \"Observations of NGC 4258 reveal a supermassive black hole at its center.\",\n",
    "    \"The Hubble Space Telescope captured images of the Andromeda Galaxy.\",\n",
    "    \"SN 2023ixf was discovered in the Pinwheel Galaxy M101.\",\n",
    "    \"This paper discusses stellar formation in the Orion Nebula.\"\n",
    "]\n",
    "\n",
    "test_model_predictions(final_model, sample_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training History Visualization and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_training_history(history: Dict[str, List[float]], title: str = \"Training History\"):\n",
    "    \"\"\"Analyze and display training history.\n",
    "    \n",
    "    Args:\n",
    "        history: Training history dictionary\n",
    "        title: Title for the analysis\n",
    "    \"\"\"\n",
    "    print(f\"\\n{title}\")\n",
    "    print(\"-\" * len(title))\n",
    "    \n",
    "    epochs = len(history['val_f1'])\n",
    "    print(f\"Total epochs: {epochs}\")\n",
    "    \n",
    "    if epochs > 0:\n",
    "        print(f\"Final validation F1: {history['val_f1'][-1]:.4f}\")\n",
    "        print(f\"Best validation F1: {max(history['val_f1']):.4f}\")\n",
    "        print(f\"Final training loss: {history['train_loss'][-1]:.4f}\")\n",
    "        \n",
    "        # Check for overfitting\n",
    "        if epochs >= 5:\n",
    "            recent_f1_trend = history['val_f1'][-5:]\n",
    "            if len(recent_f1_trend) >= 2 and recent_f1_trend[-1] < recent_f1_trend[0]:\n",
    "                print(\"  Potential overfitting detected (F1 declining)\")\n",
    "            else:\n",
    "                print(\" No obvious overfitting detected\")\n",
    "\n",
    "# Analyze baseline and final model training\n",
    "analyze_training_history(baseline_history, \"Baseline Model Training\")\n",
    "analyze_training_history(final_history, \"Final Model Training\")\n",
    "\n",
    "# Create summary DataFrame of hyperparameter search results\n",
    "if search_results:\n",
    "    search_df_data = []\n",
    "    for result in search_results:\n",
    "        row = {\n",
    "            'dropout': result['config']['dropout'],\n",
    "            'learn_rate': result['config']['learn_rate'],\n",
    "            'n_iter': result['config']['n_iter'],\n",
    "            'final_f1': result['scores']['f1'],\n",
    "            'final_precision': result['scores']['precision'],\n",
    "            'final_recall': result['scores']['recall']\n",
    "        }\n",
    "        search_df_data.append(row)\n",
    "    \n",
    "    search_df = pd.DataFrame(search_df_data)\n",
    "    search_df = search_df.sort_values('final_f1', ascending=False)\n",
    "    \n",
    "    print(\"\\nHyperparameter Search Results (Top 5):\")\n",
    "    print(search_df.head().to_string(index=False, float_format='%.4f'))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Final model saved to: {model_path}\")\n",
    "print(f\"Best configuration: {best_config}\")\n",
    "print(f\"Test F1 Score: {evaluation_results['spacy_scores']['f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Training Results and Model Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training results and metadata\n",
    "results_data = {\n",
    "    'model_info': {\n",
    "        'model_path': str(model_path),\n",
    "        'training_date': pd.Timestamp.now().isoformat(),\n",
    "        'labels': list(all_labels),\n",
    "        'total_training_examples': len(training_data)\n",
    "    },\n",
    "    'data_splits': {\n",
    "        'train_size': len(train_data),\n",
    "        'val_size': len(val_data), \n",
    "        'test_size': len(test_data)\n",
    "    },\n",
    "    'best_config': best_config,\n",
    "    'test_performance': evaluation_results['spacy_scores'],\n",
    "    'training_history': final_history,\n",
    "    'hyperparameter_search': search_results if 'search_results' in locals() else None\n",
    "}\n",
    "\n",
    "results_path = MODELS_DIR / \"training_results.json\"\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump(results_data, f, indent=2, default=str)\n",
    "\n",
    "print(f\"Training results saved to: {results_path}\")\n",
    "print(\"\\n ML Pipeline completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = baseline_model(val_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entity in doc1.ents:\n",
    "  print(entity.label_, ' | ', entity.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entities': [(116, 123, 'ASTRO_OBJ')]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data[2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NGC 652'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data[2][0][116:123]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
